{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈 분류\n",
    "- 특성들 사이의 독립을 가정하는 베이즈 정리를 적용한 확률 분류기의 일종"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류는 지도학습이기 때문에 라벨이 있어야 한다\n",
    "train = [\n",
    "    ('i like you','pos'),\n",
    "    ('i hate you','neg'),\n",
    "    ('you like me','neg'),\n",
    "    ('i like her','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate', 'her', 'i', 'like', 'me', 'you'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#말 뭉치 구성\n",
    "all_words = set(\n",
    "    word.lower() for sentence in train for word in word_tokenize(sentence[0])\n",
    ")\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "말뭉치를 이용해서 train에 있는 문장들을 만들 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'i': True,\n",
       "   'like': True,\n",
       "   'me': False,\n",
       "   'hate': False,\n",
       "   'her': False,\n",
       "   'you': True},\n",
       "  'pos'),\n",
       " ({'i': True,\n",
       "   'like': False,\n",
       "   'me': False,\n",
       "   'hate': True,\n",
       "   'her': False,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'i': False,\n",
       "   'like': True,\n",
       "   'me': True,\n",
       "   'hate': False,\n",
       "   'her': False,\n",
       "   'you': True},\n",
       "  'neg'),\n",
       " ({'i': True,\n",
       "   'like': True,\n",
       "   'me': False,\n",
       "   'hate': False,\n",
       "   'her': True,\n",
       "   'you': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [\n",
    "    ({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train\n",
    "]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 특성들을 전부 독립으로 본다는 나이브 베이즈 분류의 특징이 나타난다.\n",
    "이렇게 각 단어별로 독립적으로 확률을 계산하기 때문에 naive하다고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 완료했으니 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': True,\n",
       " 'like': True,\n",
       " 'me': False,\n",
       " 'hate': False,\n",
       " 'her': False,\n",
       " 'you': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i like Merui'\n",
    "\n",
    "test_feature = {\n",
    "    word.lower(): (word in word_tokenize(test_sentence.lower())) for word in all_words\n",
    "}\n",
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것이 감성 분석의 과정이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글로 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    ('메리가 좋아','pos'),\n",
    "    ('고양이도 좋아','pos'),\n",
    "    ('난 수업이 지루해','neg'),\n",
    "    ('메리는 이쁜 고양이야','pos'),\n",
    "    ('난 마치고 메리랑 놀거야','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#말뭉치 만들기\n",
    "all_words = set(\n",
    "word for sentence in train for word in word_tokenize(sentence[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이도',\n",
       " '고양이야',\n",
       " '난',\n",
       " '놀거야',\n",
       " '마치고',\n",
       " '메리가',\n",
       " '메리는',\n",
       " '메리랑',\n",
       " '수업이',\n",
       " '이쁜',\n",
       " '좋아',\n",
       " '지루해'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '난': False,\n",
       "   '메리는': False,\n",
       "   '고양이도': False,\n",
       "   '마치고': False,\n",
       "   '메리랑': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': True,\n",
       "   '지루해': False,\n",
       "   '좋아': True,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '난': False,\n",
       "   '메리는': False,\n",
       "   '고양이도': True,\n",
       "   '마치고': False,\n",
       "   '메리랑': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '좋아': True,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이야': False,\n",
       "   '놀거야': False,\n",
       "   '난': True,\n",
       "   '메리는': False,\n",
       "   '고양이도': False,\n",
       "   '마치고': False,\n",
       "   '메리랑': False,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '지루해': True,\n",
       "   '좋아': False,\n",
       "   '수업이': True},\n",
       "  'neg'),\n",
       " ({'고양이야': True,\n",
       "   '놀거야': False,\n",
       "   '난': False,\n",
       "   '메리는': True,\n",
       "   '고양이도': False,\n",
       "   '마치고': False,\n",
       "   '메리랑': False,\n",
       "   '이쁜': True,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '좋아': False,\n",
       "   '수업이': False},\n",
       "  'pos'),\n",
       " ({'고양이야': False,\n",
       "   '놀거야': True,\n",
       "   '난': True,\n",
       "   '메리는': False,\n",
       "   '고양이도': False,\n",
       "   '마치고': True,\n",
       "   '메리랑': True,\n",
       "   '이쁜': False,\n",
       "   '메리가': False,\n",
       "   '지루해': False,\n",
       "   '좋아': False,\n",
       "   '수업이': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [\n",
    "    ({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train\n",
    "]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                    고양이도 = False             neg : pos    =      1.1 : 1.0\n",
      "                    고양이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     놀거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리가 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리는 = False             neg : pos    =      1.1 : 1.0\n",
      "                     메리랑 = False             neg : pos    =      1.1 : 1.0\n",
      "                      이쁜 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'고양이야': False,\n",
       " '놀거야': True,\n",
       " '난': True,\n",
       " '메리는': False,\n",
       " '고양이도': False,\n",
       " '마치고': False,\n",
       " '메리랑': True,\n",
       " '이쁜': False,\n",
       " '메리가': False,\n",
       " '지루해': False,\n",
       " '좋아': False,\n",
       " '수업이': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀거야'\n",
    "\n",
    "test_feature = {\n",
    "    word.lower(): (word in word_tokenize(test_sentence.lower())) for word in all_words\n",
    "}\n",
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍정적인 문장으로 테스트했는데 neg가 나왔다. 왜그럴까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글은 작은 조사 하나때문에 어감이 달라지기 때문에 형태소 분석이 필수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n",
       " (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n",
       " (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n",
       " (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs = [(tokenize(row[0]), row[1]) for row in train]\n",
    "train_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메리/Noun',\n",
       " '가/Josa',\n",
       " '좋다/Adjective',\n",
       " '고양이/Noun',\n",
       " '도/Josa',\n",
       " '좋다/Adjective',\n",
       " '난/Noun',\n",
       " '수업/Noun',\n",
       " '이/Josa',\n",
       " '지루하다/Adjective',\n",
       " '메리/Noun',\n",
       " '는/Josa',\n",
       " '이쁘다/Adjective',\n",
       " '고양이/Noun',\n",
       " '야/Josa',\n",
       " '난/Noun',\n",
       " '마치/Noun',\n",
       " '고/Josa',\n",
       " '메리/Noun',\n",
       " '랑/Josa',\n",
       " '놀다/Verb']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#형태소분석을 완료한 말뭉치 완성\n",
    "tokens = [t for d in train_docs for t in d[0]]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_exists(doc):\n",
    "    return {word: (word in set(doc)) for word in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'메리/Noun': True,\n",
       "   '가/Josa': True,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': True,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': True,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': False,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': True,\n",
       "   '이/Josa': True,\n",
       "   '지루하다/Adjective': True,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'neg'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': True,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': False,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': True,\n",
       "   '이쁘다/Adjective': True,\n",
       "   '야/Josa': True,\n",
       "   '마치/Noun': False,\n",
       "   '고/Josa': False,\n",
       "   '랑/Josa': False,\n",
       "   '놀다/Verb': False},\n",
       "  'pos'),\n",
       " ({'메리/Noun': True,\n",
       "   '가/Josa': False,\n",
       "   '좋다/Adjective': False,\n",
       "   '고양이/Noun': False,\n",
       "   '도/Josa': False,\n",
       "   '난/Noun': True,\n",
       "   '수업/Noun': False,\n",
       "   '이/Josa': False,\n",
       "   '지루하다/Adjective': False,\n",
       "   '는/Josa': False,\n",
       "   '이쁘다/Adjective': False,\n",
       "   '야/Josa': False,\n",
       "   '마치/Noun': True,\n",
       "   '고/Josa': True,\n",
       "   '랑/Josa': True,\n",
       "   '놀다/Verb': True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian_xy = [(term_exists(d), c) for d,c in train_docs]\n",
    "trian_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  난/Noun = True              neg : pos    =      2.5 : 1.0\n",
      "                 메리/Noun = False             neg : pos    =      2.5 : 1.0\n",
      "                고양이/Noun = False             neg : pos    =      1.5 : 1.0\n",
      "            좋다/Adjective = False             neg : pos    =      1.5 : 1.0\n",
      "                  가/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  고/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                 놀다/Verb = False             neg : pos    =      1.1 : 1.0\n",
      "                  는/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  도/Josa = False             neg : pos    =      1.1 : 1.0\n",
      "                  랑/Josa = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trian_xy)\n",
    "classifier.show_most_informative_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('난', 'Noun'),\n",
       " ('수업', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('마치', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('메리', 'Noun'),\n",
       " ('랑', 'Josa'),\n",
       " ('놀거야', 'Verb')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '난 수업이 마치면 메리랑 놀거야'\n",
    "\n",
    "test_docs = pos_tagger.pos(test_sentence)\n",
    "\n",
    "test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('난', 'Noun'): False,\n",
       " ('수업', 'Noun'): False,\n",
       " ('이', 'Josa'): False,\n",
       " ('마치', 'Noun'): False,\n",
       " ('면', 'Josa'): False,\n",
       " ('메리', 'Noun'): False,\n",
       " ('랑', 'Josa'): False,\n",
       " ('놀거야', 'Verb'): False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature = {word: (word in tokens) for word in test_docs}\n",
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
